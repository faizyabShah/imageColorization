{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msQM4oFfbjeV"
      },
      "outputs": [],
      "source": [
        "#Google Colab Link: https://colab.research.google.com/drive/18Q7wLrFuXruZ2OulBggtHUlm1dZH8Sw3?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "E6vWb4v1cTFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/l3llff/flowers\")"
      ],
      "metadata": {
        "id": "12XLRRSNc6-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf /content/lfwpeople/lfw-funneled.tgz"
      ],
      "metadata": {
        "id": "aKskHf909jKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KJ3ZJwl48pq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, UpSampling2D, BatchNormalization, Activation, Dropout\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T6AKt4T5iSm"
      },
      "outputs": [],
      "source": [
        "path = '/content/flowers'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train = train_datagen.flow_from_directory(path, target_size=(128, 128), batch_size=5000, class_mode=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J00nkJhE6-YO"
      },
      "outputs": [],
      "source": [
        "X =[]\n",
        "Y =[]\n",
        "i = 0\n",
        "for img in train[0]:\n",
        "    try:\n",
        "        lab = rgb2lab(img)\n",
        "        X.append(lab[:,:,0])\n",
        "        Y.append(lab[:,:,1:] / 128 )\n",
        "        i += 1\n",
        "    except:\n",
        "      print('error')\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "X = X.reshape(X.shape+(1,))\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train"
      ],
      "metadata": {
        "id": "DHfzBzxisStd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdfz9n027DJN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=True, input_shape=(None, None, 1)))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', dilation_rate=2, use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', dilation_rate=2, use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', dilation_rate=2, use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', dilation_rate=2, use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', dilation_rate=2, use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', dilation_rate=2, use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', use_bias=True))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(313, kernel_size=1, strides=1, padding='valid', use_bias=True))\n",
        "\n",
        "softmax_layer = tf.keras.layers.Softmax(axis=3)\n",
        "model.add(softmax_layer)\n",
        "\n",
        "output_layer = tf.keras.layers.Conv2D(2, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
        "model.add(output_layer)\n",
        "\n",
        "upsample_layer = tf.keras.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')\n",
        "model.add(upsample_layer)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ut30TuLBinGz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElzOS1KQ7OQz"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ue9b4zu7NgN"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
        "model.compile( loss='mse' , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRVxKvT_5fkT"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X,Y,validation_split=0.1, epochs=30, batch_size=16)\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVRAsQwRab44"
      },
      "outputs": [],
      "source": [
        "model.save('/content/test.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQRt191a-oDh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('flowers.h5')"
      ],
      "metadata": {
        "id": "D5eyryKxYwpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkigMShhORtV"
      },
      "outputs": [],
      "source": [
        "def predict(filename):\n",
        "  img1_color=[]\n",
        "  img1=img_to_array(load_img(filename))\n",
        "  img1 = resize(img1 ,(128,128))\n",
        "  img1_color.append(img1)\n",
        "  img1_color = np.array(img1_color, dtype=float)\n",
        "  img1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
        "  img1_color = img1_color.reshape(img1_color.shape+(1,))\n",
        "  output1 = model.predict(img1_color)\n",
        "  output1 = output1*128\n",
        "  result = np.zeros((128, 128, 3))\n",
        "  result[:,:,0] = img1_color[0][:,:,0]\n",
        "  result[:,:,1:] = output1[0]\n",
        "  img= load_img(filename)\n",
        "  img2 = lab2rgb(result)\n",
        "  Titles =[\"Original\", \"Prediction\"]\n",
        "  images =[img, img2]\n",
        "  count = 2\n",
        "\n",
        "  for i in range(count):\n",
        "      plt.subplot(1, 2, i + 1)\n",
        "      plt.title(Titles[i])\n",
        "      plt.imshow(images[i])\n",
        "\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f8_1F_p6AJ3"
      },
      "outputs": [],
      "source": [
        "predict('/content/testyyy.jpg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}